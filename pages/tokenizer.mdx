---
title: 'The Terrific Tokenizer'
blurb: 'How does a tokenizer convert a code string into a list of tokens?'
publishedAt: '2021-12-21'
editedAt: '2021-12-21'
---

import { Boilerplate } from '@/components/compiler/Boilerplate'
import { Tokenizer } from '@/components/compiler/Tokenizer'
import { PageList } from '@/components/compiler/PageList'
import { Editor } from '@/components/compiler/Editor'
import { Reveal } from '@/components/Reveal'
import { Svg } from '@/components/Svg'
import Figure from '@/elements/Figure'
import Callout from '@/elements/Callout'
import ProblemStatement from '@/elements/ProblemStatement'

A few weekends ago, I spent some time rebuilding the Babel compiler from scratch to learn a bit more about how it works internally. You see, I already knew a _bit_ about compilers and talked about them briefly in my [debugger]() post, but there was a very large knowledge gap that was apparent to me. I knew how to manipulate an abstract syntax tree, but I didn't know _how to make one_.

Fundamentally, I see a compiler as a pipeline with four concrete steps:

<Figure size="xl">
  <Svg href="tokenizer/pipeline.svg" />
</Figure>

Each step takes in the output of the previous step and transforms it to something else. The first step, the tokenization step, takes in your original source code as its input, while the last step, the generation step, spits out the modified code.

In this post, we'll go over how to build a tokenizer for a small subset of JavaScript. Specifically, we'll build a tokenizer that can understand the following code snippet _and absolutely nothing more_:

```ts
function hello() {
  console.log('hello, world!')
}
```

## Tokens Are the Language's Words

But wait — what's a token and what does a tokenizer actually _do_?

Essentially, a tokenizer breaks up your source code into small objects called **tokens** (hence the name). I like to think of a token as a "word" in the programming language, i.e. the smallest sequence of characters that still carry a meaning.

For example, if you tokenize the following JavaScript code:

```js
console.log(message)
```

You'll end up with the following six tokens:

```
[console] [.] [log] [(] [message] [)]
```

Just like how a word in english can be a noun, verb, adjective, etc., each token has a type that represents that token's meaning. In our previous example, those types might be something like:

```
[console]   [.]  [log]       [(]        [message]   [)]
 Identifier  Dot  Identifier  LeftParen  Identifier  RightParen
```

To reiterate, the tokenizer's job is to break up the source code (which it receives as a string) into a list of tokens like we just saw. Breaking up the code like this makes the other phases' lives much easier — instead of working with the source string directly, they work with the neat and tidy list of tokens.

## Implementation Plan

Great! Now that we know what a tokenizer is, we're finally ready to implement our tokenizer. Again, we want to focus on tokenizing the following code snippet and nothing more:

```ts
function hello() {
  console.log('hello, world!')
}
```

And here's a preview of the final product making its way through our tokenizer:

<Figure size="lg">
  <Tokenizer />
</Figure>

We'll break down the implementation into three parts:

1. Parsing single character tokens;
2. Parsing identifiers and keywords; and
3. Parsing string literals.

Let's get started!

## Single Character Tokens

Let's begin by trying to parse out the simplest tokens first - the ones that are only one character long. In the code snippet we're parsing, that would be the dot, curly brackets and left parentheses tokens:

<Figure size="lg">

![](tokenizer/single-tokens.png)

</Figure>

We'll start off by iterating through every character of our input:

<Figure size="lg">
  <Boilerplate />
</Figure>

<Callout label="What's that \n?">

The `\n` character is a special character that represents a **new line**. It's typically invisible to us when we're editing code or text, but I chose to explicitly show it here to show what the _computer_ sees.

</Callout>

As we iterate through the code string, we check if the current character is one of these single character tokens, and if it does, we add the character to the final tokens list.

One way to check if a character is a single character token is to keep a list of all single character tokens we support and checking if the character is in that list:

<Figure size="lg">Test</Figure>

## Identifiers and Keywords

With the single character tokens out of the way, the next thing we have to do is to parse the identifier and keyword tokens. But hold on a second - what's an identifier anyway?

### What Makes an Identifier?

In JavaScript, an identifier is a sequence of characters that is used to refer to some piece of data. For example, in our input code snippet, the words `hello`, `console`, and `log` are all identifiers because they refer to a function definition, an object, and a method respectively (all data available to the program).

[According to MDN](https://developer.mozilla.org/en-US/docs/Glossary/Identifier), a _valid_ identifier in JavaScript is a sequence of alphanumeric characters, except the first character cannot be a number. This means the following strings are valid identifiers:

```
hello
_abc
abc123
```

But the following are not:

```
2cool
8ball
```

I initially wanted to support the MDN identifier rules exactly, but I chose to limit identifiers to only **alphabetical** characters for now. This means that, out of all the examples above, my tokenizer will only recognize the word `hello` as an identifier.

### Implementation

To recap, an identifier (for our purposes) is any sequence of alphabetical characters. To parse it, I went with the following approach:

1. If the current character is alphabetical, start parsing an identifier;
2. Keep adding characters to the current identifier token until the current character is **not** alphabetical.

<Figure size="lg"></Figure>

### Keywords

Some identifiers have a special meaning in JavaScript and therefore cannot be used to refer to a piece of data, such as `function`, `while`, and `switch`. This group of identifiers are called **keywords** and typically have their own individual token types.

Therefore...

<ProblemStatement>
  How does the tokenizer differentiate between an identifier and a keyword?
</ProblemStatement>

One way is to do the same thing as the single character tokens:

1. Keep a set of known keywords;
2. When we're parsing an identifier, check if the parsed name is in this set;
3. If it is, change the token's type to the keyword's type.

<Figure size="lg">keywords</Figure>

## String Literals

Next up is tokenizing **string literals**.

## Whitespace

Great! So far, our identifier can identify single character, identifier, and keyword tokens. The last thing we need to take care of is _whitespace_. We don't really want to do anything with whitespace, so the only change here is to skip the current character if it's a whitespace character.

<Figure size="lg">Ignore whitespace</Figure>

## Summary

And there we have our tokenizer! It can't do too much at the moment, but it's able to tokenize the code snippet that we started with:

```js
function hello(message) {
  console.log(message)
}
```

I purposely omitted code snippets because I wanted to solidify the _concepts_ behind a tokenizer rather than tying it down to any direct implementation. After all, there's a bunch of different ways of implementing the same thing! But if you'd like to see an implementation, check out [my implementation of this tokenizer (written in TypeScript)](https://github.com/narendrasss/compiler/blob/main/src/tokenizer.ts).

To finish off, I have a few exercises for you to try out if you'd like to learn more:

1. **Implement this tokenizer in your language of choice**; use the visualization from the introduction as a reference.
2. Once it's done, **extend the tokenizer to support the following syntax**: `const hello = 'world'`.

I'd love to see what you come up with, and thanks for reading!
